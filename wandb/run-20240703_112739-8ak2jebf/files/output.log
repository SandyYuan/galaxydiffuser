/global/common/software/desi/users/sihany/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
0: 2.556760549545288, delta_t: 11.963
sampling loop time step:   1%|          | 12/1000 [00:01<01:36, 10.27it/s]



















































sampling loop time step: 100%|██████████| 1000/1000 [01:43<00:00,  9.70it/s]
1: 2.5235681533813477, delta_t: 113.378
1: 2.5245633125305176, delta_t: 9.939
2: 2.426068067550659, delta_t: 9.857
2: 2.4234094619750977, delta_t: 9.860
3: 2.387904405593872, delta_t: 9.758
3: 2.387958526611328, delta_t: 9.925
4: 2.379718542098999, delta_t: 9.940
4: 2.381260395050049, delta_t: 9.808
5: 2.364348888397217, delta_t: 9.834
5: 2.3638360500335693, delta_t: 10.076
6: 2.3519515991210938, delta_t: 9.840
6: 2.353964328765869, delta_t: 9.932
7: 2.3437116146087646, delta_t: 9.852
7: 2.340364456176758, delta_t: 10.017
8: 2.3170855045318604, delta_t: 9.803
8: 2.3079094886779785, delta_t: 9.838
9: 2.288815975189209, delta_t: 9.803
9: 2.300813674926758, delta_t: 9.829
10: 2.2422261238098145, delta_t: 9.793
10: 2.250656843185425, delta_t: 9.888
11: 2.2295870780944824, delta_t: 9.910
11: 2.2146384716033936, delta_t: 10.029
12: 2.1875295639038086, delta_t: 9.989
12: 2.1852166652679443, delta_t: 10.032
13: 2.1771016120910645, delta_t: 9.894
13: 2.1717686653137207, delta_t: 9.898
14: 2.142451763153076, delta_t: 9.828
14: 2.137749671936035, delta_t: 9.897
15: 2.106790065765381, delta_t: 9.841
15: 2.0838372707366943, delta_t: 9.830
16: 2.0787546634674072, delta_t: 9.826
16: 2.0735435485839844, delta_t: 9.841
17: 2.0344512462615967, delta_t: 9.924
17: 2.054492473602295, delta_t: 9.925
18: 2.0163397789001465, delta_t: 9.853
18: 2.0263514518737793, delta_t: 9.954
19: 1.9966474771499634, delta_t: 9.888
19: 1.9764660596847534, delta_t: 9.830
20: 1.9692368507385254, delta_t: 9.867
20: 1.983590841293335, delta_t: 9.882
21: 1.9582868814468384, delta_t: 9.947
21: 1.9265568256378174, delta_t: 9.785
22: 1.9125630855560303, delta_t: 9.876
22: 1.913614273071289, delta_t: 9.797
23: 1.877732753753662, delta_t: 9.773
23: 1.8481638431549072, delta_t: 9.884
24: 1.8502957820892334, delta_t: 9.897
24: 1.8806829452514648, delta_t: 9.789
25: 1.8198177814483643, delta_t: 9.889
25: 1.815677285194397, delta_t: 9.877
26: 1.7821025848388672, delta_t: 9.817
26: 1.7563245296478271, delta_t: 9.812
27: 1.723933219909668, delta_t: 9.939
27: 1.7325400114059448, delta_t: 9.814
28: 1.7134692668914795, delta_t: 9.902
28: 1.7011222839355469, delta_t: 9.905
29: 1.6919970512390137, delta_t: 9.931
29: 1.6800222396850586, delta_t: 9.822
30: 1.7067286968231201, delta_t: 9.875
30: 1.6693264245986938, delta_t: 9.856
31: 1.691375494003296, delta_t: 9.821
31: 1.7121760845184326, delta_t: 9.813
32: 1.6170899868011475, delta_t: 9.924
32: 1.6259256601333618, delta_t: 9.810


























